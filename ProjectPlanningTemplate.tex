\newcommand{\comment}[1]{}

%\documentclass[a4paper,twocolumn,12pt]{article}

%\documentclass[a4wide,12pt]{report}

%\documentclass[a4wide,12pt]{article}
%\documentclass[informasjonssikkerhet]{gucmasterproject}
%\documentclass[informationsecurity]{gucmasterproject}
\documentclass[informationsecurity]{gucmasterproject}

%\usepackage{pslatex} %% Doesn't seem to work - i.e. convert .eps to .pdf
 
\usepackage{enumitem}
\usepackage[table]{xcolor}
\usepackage[utf8]{inputenc}     % For utf8 encoded .tex files
%\usepackage[latin1]{inputenc}
\usepackage[british]{babel}     % For chapter headings etc.
%\usepackage[pdftex]{graphicx}           % For inclusion of graphics

%From http://math.uib.no/it/tips/
   %% For grafikk
    \usepackage{ifpdf}
    \ifpdf
      \usepackage[pdftex]{graphicx}
      \usepackage{epstopdf}
    \else
      \usepackage[dvips]{graphicx}
    \fi
    %% Her kan du putte dine vanlige pakker og definisjoner



%\usepackage[dvips]{hyperref}    % For cross references in pdf
\usepackage{hyperref}
\usepackage{mdwlist}
\usepackage{url}
\usepackage{here}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{pgfgantt}
\usepackage{lscape}
\usepackage{cleveref}

\def\UrlFont{\tt}

\begin{document}

\thesistitle{Combining Periodic and Continuous Authentication}
\thesisauthor{Per-Kristian Nilsen}
\thesisdate{\gucmasterthesisdate}
\useyear{2017}
\makefrontpages % make the frontpages
%\thesistitlepage % make the ordinary titlepage


\comment{
Front page - including
"   NTNU technical report front page including logos etc.
"   The text: "MSc project plan"
"   Title of project
"   Name of author and contact details
"   Date
"   Version

email address
"   MIS students must include "NISlab" as their affiliation.
Date:22.10.2003

Structure of MSc thesis project plan
NTNU in Gj\{ovik
}


\chapter*{Revision history}

\begin{center}
\begin{tabular}[H]{|l|p{35em}|}
\hline
Version \#  & Description of change (why, what where - a few sentences)\\
\hline
      0.1   & First version made available via Fronter\\
\hline
      0.2   & Corrected some spelling mistakes and added 'control questions' to Abstract, chapter 1 and 2\\
\hline
      0.2.1   & Removed the reference to a dead link in chapter 1 (keywords).\\
\hline
      0.2.1   & Replaced HIG logo by NTNU logo (just in case it is not done!) and removed references to information security\\
	\hline
\end{tabular}
\end{center}
\newpage

\begin{abstract}
Abstract (1/2 page)
This document provides format and guidelines  for the 
MSc project descriptions. The document has been produced using MikTeX and TeXnicCenter.

The objective of the abstract is to provide the reader with an understanding of the work to be done and put him in the position to make a 'correct' decision regarding  reading/not reading the report.

The abstract of the project description
{\em must} include
\begin{itemize}
\item a summary of the problem description,
\item motivation and 
\item a summary of the planned contribution from the master project in terms of {\em new} results.
\end{itemize}

\paragraph{Control questions}
\begin{enumerate}
\item Does the abstract have a 'reasonable' length?
\item Is it clear to a non expert (e.g. a typical reader of a newspaper) what problem is addressed?
\item Does a person that has been working in the field find the text informative?
\item Do the results that might be obtained have the potential to be interesting to a lot of people? How interesting to how many and why?
\item Would a decision maker/manager be willing to pay NOK 400.000 to have the project completed (estimated salary costs + overheads) after having read the abstract?  Why/why not?
\end{enumerate}

\end{abstract}


\tableofcontents

%\chapter{Contents of the project description}
%The project description must use the gucmasterproject class file and contain the following elements/chapters:
%\begin{itemize}
%\item[] Front page
%\item[] Table of contents
%\item[] Abstract
%\item[1] Introduction
%\item[1.1] Topic covered
%\item[1.2] Keywords
%\item[1.3] Problem description
%\item[1.4] Justification motivation and benefits
%\item[1.5] Research questions
%\item[1.6] Planned contributions
%\item[2]Related work
%\item[3] Choice of methods
%\item[4]Milestones, deliverables and resources
%\item[5]Feasibility study
%\item[6]Risk analysis
%\item[7]Ethical and legal considerations
%\item[] Bibliography
%\item[] Appendix
%\item[A] Acronyms and abbreviations
%
%\end{itemize}
%
%Each chapter must contain the information specified in this document and further explained in 
%lectures or included in lecture notes.

\chapter{Introduction (1-2 pages)}

\section{Topic covered by the project}
\label{sec:topic}
When a person attempts to access certain resources or systems, they may need to verify that they are in fact authorized to do so, often through an authentication mechanism.
Authentication is the act of verifying that the current user matches the identity they are claiming ownership of.
After claiming an identity, for example by providing a username, the current user may support their claim by presenting something only the true owner of the identity is supposed to \textit{know} or \textit{have}.
This could for example be a password or a token such as a key card.
The user may also give a representation of what they \textit{are}, which bring us to the topic of \textit{biometrics}.

Biometric systems measure human characteristics to determine the identity of users.
While biological biometrics is now widely embedded in our everyday lives such as fingerprint scanning and lately face recognition in our smart phones, we can also be identified by the way we behave by means of \textit{behavioral biometrics}.
Voice and gait recognition are examples of behavioral biometrics, however the topic of this project revolves around \textit{keystroke dynamics} which involves measuring a user's typing patterns on a keyboard.
Every individual has their own way of typing on computer keyboards, and this can be taken advantage of by authenticating users by measuring the angle, pressure or timings of keypresses, which the latter will be our focus.
Examples of such timings can be the time of when keys are pressed or released. 

Authentication can be used both for giving access (\textit{static authentication}) and removing access (\textit{dynamic authentication}).
When a user claims an identity and writes the correct password, the biometric system can compare the typing pattern in the written password to the way the true owner of the identity writes the same password.
If the patterns match, they may be given access.
This is an example of static authentication using \textit{fixed-text} keystroke dynamics.

Keystroke dynamics can also be used for dynamic authentication.
Even after a user is logged into a given system using \textit{static authentication}, they can continue being authenticated by a background process after the initial log-in, removing their access if they are believed to be an imposter.
Dynamic authentication based on keystroke dynamics can be done by two different methods: \textit{periodic} or \textit{continuous authentication}.
With periodic authentication (PD), the system collects keystroke timing information over a period of time, and retroactively analyses the collected data.
It will then analyze the statistical properties derived from the data, decide if they fit the properties of the genuine user and remove access if they do not fit.
Systems with continuous authentication (CA) will check if the user is genuine after each action they perform.

Authors of PD systems generally refer to their systems as \textit{continuous authentication}, however we will in this project refer to them as \textit{periodic authentication}. 
The reason for this is that the word "continuous" implies checks being performed after every action, while PA systems require a greater number of actions before the check is initiated. 
This was first pointed out by Patrick Bours \cite{BOURS201236} in his CA study.

A great benefit to CA is that the system can make a decision every time the user presses a key, whereas impostors have time to perform a certain amount of potentially harmful keystroke actions in-between identity verifications in PA systems.
On the other hand, CA systems can not take advantage of statistical analysis like PA systems can.
Therefore, we would like to investigate if extending an existing CA system with PA system can remove the inherent disadvantages of both types of systems as well as significantly improve the performance of the CA system.


% This section specifies the general area of the project.
%It should preferably be understandable by everybody,
%also those not familiar with the field. (e.g. all your relations and friends).
%
%The purpose of the topic section is to:
%\begin{itemize}
%\item Very quickly give the reader some idea of the perspective taken
%with respect to problem addressed.  
%\item Help a reader to decide if the project
%is within the readers area of interest and scope.
%\item Help the author (you!) to see if he has the necessary skills,
%if he/she needs to get access to specific expertise etc.
%Do you have the right skills/ background/ knowledge
%to be able to carry out the project?
%\end{itemize}
%
%\paragraph{Control questions:}
%\begin{enumerate}
%\item Does it have the right length?
%\item Is it focused or is it just a non-focused brain dump going all over the place?
%\item Is it clear from the text what skills would be required/beneficial in order to do/participate in the project?
%\end{enumerate}


\section{Keywords}
Behavioral biometrics; keystroke dynamics; continuous authentication; periodic authentication; intrusion detection; distance-based classification; machine learning 
%There are several sources of keywords. Rather than 'inventing your own' you should select an appropriate set of keywords from a reputable source such as the one published by the IEEE computer society (IEEE Computer Society - Keywords) or ACM (ACM Computing Classification System).
%%\protect\url{http://www.computer.org/portal/site/ieeecs/menuitem.c5efb9b8ade9096b8a9ca0108bcd45f3/index.jsp?&pName=ieeecs_level1&path=ieeecs/publications/author/keywords&file=ACMtaxonomy.xml&xsl=generic.xsl&},
%The taxonomy by Avizienis et al\cite{Avizienis2004} provides an overview of of the subject area and an alternative set of keywords/classifications.
%
%\paragraph{Control questions:}
%\begin{enumerate}
%\item Does the collection of keywords 'pin down' the project or is it to 'wide'?
%\item Are the keywords too specific, making it difficult  for people with a closely related interest to recognize the keywords?
%\item Why is it likely that a person working in the field would use the keywords you have selected when doing a search in this area?
%\item Is the number of keywords appropriate?
%\end{enumerate}

\section{Problem description}
While many systems and applications rely on static authentication such as log-in processes, most systems do not perform further authentication to ensure that the current user has not changed since logging in.
Physically leaving an unlocked computer unattended is not an uncommon practice in many work environments, which opens up for free and unauthorized access by anyone willing to seize the opportunity.
The longer the genuine user is absent, the more time unauthorized users have to access information or cause damage to any part of the system.
Restricting the amount of actions intruders can perform is therefore needed in order to reduce the damage potential.

To the best of our knowledge, there has been no research conducted on combining CA and PA for keystroke dynamics.
Because of this, the drawbacks of both types of systems are present in literature.
As stated earlier, a disadvantage to PA systems is that there is a window of time where an imposter can use the system before the next identity verification is performed.
Most of the existing PA systems need several hundreds to over one thousand keystrokes for every periodic authentication.
This leaves the imposter with too much freedom before their access is removed.

The main problem with CA systems is that they need to base their decisions on a very small amount of information about the current user's typing pattern.
Every action is continuously classified as an imposter action or a genuine action. 
That means that CA systems are not able to rely on statistics from the current user's typing pattern.

Both CA and PA systems share another common problem, being that they can make errors.
More specifically, they may wrongfully believe that the genuine user is an imposter, or they may mistake an imposter for being the genuine user.
In real-time implementations of such systems, the first case would lead to access being removed from the genuine user, which would be a source of irritation or frustration.
The second case would give an imposter time to perform more keystrokes before (hopefully) having their access removed at a later point.

Both systems take a certain amount of time to detect imposters.
While PA systems generally need a fixed amount of recorded keystrokes before analyzing them, CA systems remove access when they no longer trust the genuineness of the user.
Every keystroke increases or decreases the CA system's trust level, and the more similar the current user's typing pattern is to that of the genuine user, the longer they are allowed to remain logged in. 
Therefore, an important problem to solve is to decrease the number of keystrokes imposters are allowed to perform before having their access removed, while also allowing genuine users to perform as many keystrokes as possible before being wrongfully locked out.

%These PA systems also have varying performance.
%Many systems report their accuracy using False Accept Rate (FAR) and False Reject Rate (FRR), though I will refer to the rates as False Match Rate (FMR) and False Non-Match Rate (FNMR), as these are the correct terms for algorithm-level performance rates according to the ISO/IEC 2382-37 standard.
%While these rates vary between systems, they tend to stay below 1\% FMR and around 5\% FNMR, meaning imposters are wrongfully believed to be the genuine user in 1\% of verification attempts, while the genuine user is wrongfully believed to be an imposter in 5\% of such cases.

%These numbers are only given meaning when seen in combination with the number of keystrokes needed per authentication.
%If the authentication is performed every 1000 keystrokes, 5\% FNMR can be acceptable, as this would not result in many false non-matches per day.
%However, if the authentication is triggered at shorter intervals, the genuine user is rejected and logged out so frequently that the PA system becomes a nuisance.


%Use last sentence of topic description

%What's 'wrong' with the world we're living in? E.g.
%\begin{itemize}
%\item   Something is currently too difficult.
%\item   Something is broken/doesn't work properly.
%\item   Something is currently to expensive, difficult, costly etc.
%\end{itemize}
%
%\paragraph{Control questions:}
%\begin{enumerate}
%\item Does it have an appropriate length?
%\item Would it be possible to explain the problem description to a non-expert/expert in say 2 minutes in such a way that it was understood?
%\item If explained to different people, would they have a common understanding?
%\item If you were to check if your problem description was understood, what question(s) would you ask?
%\item What is the information density of your text and why?
%\end{enumerate}

\section{Justification, motivation and benefits}

By achieving positive results, this project has the potential to increase the viability of free-text keystroke dynamics in industries and sectors where a higher level of security is needed or desired, such as the health sector or other critical infrastructures.
This does not exclude other work environments or even private computers, as any owner of a system where security is essential could benefit from imposters being automatically detected and locked out by typing on the keyboard.
As improving the CA system's accuracy would lead to imposters being detected more quickly while genuine users are locked out less frequently, it would lead to higher security and a better user experience.

%This section should be understandable by everybody including your family and relatives.
%In particular, it should be understandable to those who will benefit.
%NOTE : 'I want to do zz' does not count as a legitimate motivation!
%\begin{itemize}
%\item Why is important to solve the problem you have identified?
%\item Why would 'mankind' benefit from a solution to the problem identified?
%\item Who would benefit (the stakeholders)?
%\item What are the primary and secondary benefits - what's in it for the stakeholders?
%\end{itemize}
%You should try to find a journal, conference or newspaper article identifying the problem you will be adressing.
%This can be used to substantiate your claim that the problem you are adressing is significant.
%
%\paragraph{Control questions}
%\begin{enumerate}
%\item For each of the issues listed above, has the issue been addressed properly/thoroughly? 
%\item What is the information density of your text and why?
%\item If the project results was to be put in an auction when the project was completed - what price would it fetch and who would put in what bids? 
%\item What would be the overall ROI (Return On Investment) of your project if carried out?
%\end{enumerate}

\section{Research questions}\label{research:questions}
\begin{enumerate}
\item Can incorporating periodic authentication into a continuous authentication system for keystroke
dynamics significantly improve the original system's imposter detection accuracy?
%\item Can extending a continuous authentication system with periodic authentication significantly improve imposter detection accuracy?
\begin{enumerate}
\item Which incorporated PA system can lead to the best results in terms of accuracy?
\item Which incorporated PA system leads to the best results in terms of computational performance?

%\item Which combination of distance measures gives the best result in terms of accuracy?
%\item Which combination of distance measures gives the best result is terms of computational performance?
\item Should the PA and CA system make collective or separate decisions?
\end{enumerate}
\end{enumerate}
%--------------------------
%\\\\
%Describe the types of information you need in order to solve the research problem, e.g.
%We need to find out
%\begin{itemize}
%\item what factors affect  xx (where xx is the 'parameter' you want to improve, e.g. cost, time, usability, security, etc.)
%\item to what extent will activity/ method/procedure yy (where yy is some method of improving the parameter, e.g.  a program for simplifying access) improve factor xx?
%\item have somebody solved this or some closely related problem?
%\item how well has the problem been solved?
%\item what is the theoretically 'best' one can achieve?
%\end{itemize}
%
%\paragraph{Control questions:}
%\begin{enumerate}
%\item Are there any questions at all? Look for '?'...
%\item Why are the research questions relevant to the research problem?
%\item What other research questions might also be relevant?
%\item why/why not are the chosen research questions the most relevant?
%\end{enumerate}

\section{Planned contributions}
The intended contribution of this project is to extend an existing CA system with a PA system in order to improve the imposter detection accuracy of the original system.
The CA system to be extended \cite{mondal} has an Average Number of Imposter Actions (ANIA) rate of 499, meaning that it manages to detect imposters after 499 keystrokes on average. 
Furthermore it has an Average Number of Genuine Actions (ANGA) rate of 16057, which means that the genuine user is wrongfully detected as being an imposter after 16057 keystrokes on average.
By incorporating a PA system into the CA system, the aim is to improve these performance rates while keeping computational costs low enough to be used transparently on computers with the computational power of an average household laptop.
The PA system to be incorporated into the CA system is more likely to consist of a custom combination of techniques from existing research, as opposed to using an entire PA system as it is described by its original authors.
%\\\\
%---------------------
%\\\\
%A short summary of what kind of {\em new} results the master thesis will produce.  
%Ideally,  the potential novelty of the results should be justified by means of references provided.
%E.g. if an article describes the problem you will be adressing as {\em unsolved},
%you should include this reference.  Similarly, if you e.g. have some ideas on how an 
%authentication method can be improved in terms of FAR/FRR, you should specify the best
% FAR/FRR figures published and a reference to where this was published. 
% The goal of the master thesis
%will be to produce the new results identified in this section.
%
%\paragraph{Control questions}
%\begin{enumerate}
%\item Is the length of the section appropriate and why?
%\item Why/why not are the contributions 'significant'?
%\item Why/why not is it realistic that the planned contribution can be achieved?  You may want to have a look at relevant literature/ other completed master thesis to answer this question.
%\end{enumerate}

\chapter{Related work (3-10 pages)}
\label{chap:related}
This chapter aims to describe the literature relevant to the project.
In order to discuss the available literature, a few concepts from the field of biometrics must first be explained.
In order to compare the current user's characteristics to those of the genuine user, a \textit{reference} and a \textit{probe} is needed.
In the context of dynamic authentication and keystroke dynamics, the reference is a stored template of the genuine user's typing behavior recorded during the enrollment phase. 
This is the period where the biometric system learns the genuine user's characteristics.
The probe is a template of the current user's behavior, based on the keystrokes recorded during the user session.
Both of these templates are generated by extracting \textit{features} from the recorded keystrokes.

As mentioned in \Cref{sec:topic}, we will be focusing on the timing information of key actions.
The available \textit{timing feature} from a single keystroke is the \textit{dwell time}, which is a measurement of how long the key is held down.
Consecutive keystrokes are called \textit{n}-graphs, where \textit{n} is the number of keystrokes.
Features can also be extracted from these by measuring the \textit{latency} from the press/release of one key to another.

With these concepts now explained, the related literature can be presented. 
Before the relevant PA literature is described, the CA system we will be extending is summarized in \cref{sec:related-CA} in order to allow for further discussions on what PA techniques may result in a good fit.

\section{Continuous authentication}
\label{sec:related-CA}
The CA system to be extended was a part of the doctoral thesis of Soumik Mondal \cite{mondal}, where a \textit{trust model} was used to lock imposters out.
Similarly to Bours' CA study \cite{BOURS201236}, Mondal's trust model worked by comparing a single key action and digraphs (two consequtive key actions) to the genuine user's reference and having the result impact the current \textit{trust level} by means of a penalty-and-reward system.

After the initial static authentication, the user's trust level was set to 100, being the highest achievable level.
Typing patterns deviating from the reference would cause penalties in the form of lowering the trust level, while patterns complying with the reference would cause rewards to be given in the form of increasing the trust of the user's genuineness.
A threshold level was set to a value below 100, and should the current user's trust level fall below said threshold, they would be locked out.
Ideal results would have had genuine users' trust levels never dropping below the threshold, while all imposters' levels would drop below the threshold after a small amount of actions performed.

An important part of the trust model was to determine how big of a reward or penalty should be given per action performed.
For CA based on keystroke dynamics alone, Mondal \cite{mondal} presented and used an implementation of a trust model referred to as \textit{Dynamic Trust Model (DTM)}.
The size of the reward or penalty was determined by a single continuous function based on a classification score computed by comparing the probe to the reference.
The larger the difference between the classification score and an arbitrary threshold (not to be confused with the lockout threshold), the larger the penalty or reward became.
Therefore, an action with a classification score just below the threshold separating penalty and reward would only result in a small decrease in trust level.

For keystroke action classification, Mondal followed a machine learning approach and two statistical approaches.
The first statistical approach (SA-1) used Scaled Euclidian Distance (SED) for \textit{Single Key Actions} and a combination of SED and Correlation Distance for \textit{Key Digraph Actions} for calculating the classification score to be used in the DTM. 
The second statistical approach (SA-2) used the same distance metrics, but converted the distances into the classification score using fuzzy logic.
It is also worth mentioning that Bours used Scaled Manhattan Distance in his CA research \cite{BOURS201236}.
In Mondal's \cite{mondal} machine learning approach, an \textit{Artificial Neural Network}, a \textit{Counter-Propagation Artificial Neural Network} and a \textit{Support Vector Machine} were combined in a \textit{Multi-Classifier Fusion} architecture. 

The overall best machine learning results were achieved by training the classifier with data from the genuine user and from a set of imposter users, which in the original study \cite{mondal} was called Verification Process 3 (VP-3).
Testing was done with data from the genuine user which was not used for training and with data from the remaining imposters not involved in training.
This scenario is applicable in many cases, including the use on personal computers, as it shows the performance when imposters are not other users of the same system.
The performance achieved was an ANGA rating of 16057 and an ANIA rating of 499, with 1.3\% of imposters not being detected.
When compared to the best statistical approach (SA-1) having an ANGA rating of 14096 and ANIA rating of 686 with 0.9\% of imposters not detected, one could argue that the VP-3 machine learning approach performed better due to imposters being rejected faster on average, and the genuine user being rejected less often.
However, SA-1 catches a larger percentage of imposters than what VP-3 does, which certainly is an important result.
Therefore, we plan to implement both SA-1 and VP-3 in this project, as there are benefits to both.

Mondal's \cite{mondal} dataset consisted of mouse and keystroke data collected from 53 participants who were either students or university staff.
The data was collected in a completely uncontrolled manner by having the participants install a tool for logging keystrokes and mouse events on their own computers.
They were not given any specific task, ensuring that the collected data represented the participants' natural behavior.

This dataset will be used for testing the CA and PA combination, although the recorded mouse activity will not be utilized as mouse dynamics is beyond the scope of the project.
Mondal reports that it has an average of 47600 keystroke events per participant, which is a sufficient amount of data seen in relation to datasets used in PA studies.
Examples of such datasets will be described in \Cref{sec:related-other}.
%NOTE: Are these datasets described?

%An average of 700 000 events were provided per participant, of which an average of $12.4\%$ ($\pm7.7\%$) are keystroke events.
%That leaves us with an average of 86800 ($\pm53900$) keystroke events to use for testing, 

\section{Periodic authentication}
\label{sec:related-other}
There is a significant amount of available literature on PA systems.
Discussing it all is beyond the scope of this project plan. The focus will therefore mostly be on research achieving viable results using free-text authentication and having potential for being incorporated into the CA system.
This section will present the various options available to us from literature regarding methods used for PA.

A more extensive and detailed literature study is being delivered in IMT4215 Specialization Project.
The literature discussed in this section refer to their own solutions as CA, however we will refer to them as PA due to the reason stated in \Cref{sec:topic}.

\subsection{Statistical approaches}
To the best of our knowledge, incorporating a PA system into a CA system has not been done before. 
We can therefore not know the answers to our research question and subquestions before performing our own analysis of the CA/PA combination.
However, we can look at what promising results have been achieved, and how they were achieved.
This will give us indicators for how we can assemble the best combination of CA and PA.

One of the most cited articles on PA systems was written by Gunetti and Picardi \cite{gnp} and published in 2005.
They introduced the 'A' and 'R' distances, which were absolute and relative distances used for classification, and they used 2-, 3- and 4-graph latencies in their distance calculations.
Their solution is interesting due to how it accounts for variation in genuine users' typing behavior.
If a genuine user for some reason types slower than usual, for instance due to cold fingers, their typing pattern is likely to stay relatively similar to the regular pattern, only at a slower speed.
The relative distance accounts for this when comparing a probe to a reference, and is used in combination with the absolute distances of speed between the samples.
They achieved a False Match Rate (FMR) of 0.005\% and False Non-Match Rate (FNMR) of 4.833\%, meaning imposters were undetected in 0.005\% of verification processes, while genuine users were wrongfully believed to be imposters in 4.833\% of all cases. 
This was using a \textit{block size} of 700-900 keystrokes, meaning 700-900 recorded keystrokes were used to form each probe.
Block sizes this large give imposters a fairly large window of unauthorized access, and for the CA/PA combination, we would like a block size similar to the original CA system's ANIA rate, or smaller.
This is more easily expressed by converting the FMR and FNMR rates into respective ANIA and ANGA rates by means of the formulas presented in \cite{CA-performance}, where Bours and Mondal first introduced the ANIA and ANGA rates.
A middleground block size of 800 keystrokes will be used for simplicity's sake:

\begin{equation}
ANIA = \frac{block size}{(1-FMR)} = \frac{800}{(1-0.00005)} \approx 800
\end{equation}

\begin{equation}
ANGA = \frac{block size}{FNMR} = \frac{800}{0.04833} \approx 16553
\end{equation}

Genuine user's are rarely rejected with this ANGA rate, which is also the case in Mondal's \cite{mondal} CA system.
However, the ANIA rate is higher than that of the original CA system (499).
We would prefer a lower ANIA rate so that the PA system will in more cases have a chance to make a decision before the CA system has already removed access from the current user.
This way we can make more use of both authentication systems, which will hopefully impact our research subquestion regarding achieving a better accuracy.

Apart from accuracy, we must also take computational performance into account to discuss research question 1b.
Gunetti and Picardi's \cite{gnp} system used 140 seconds per authentication, which was a clear issue.
Granted, this was on a Pentium 4 processor, and more modern CPUs should provide significantly better performance.
The reason for the suffering computational performance was a sub-optimal classification algorithm which compared a probe sample to every single legal user's reference in the system, which in their experiment was 40 users.
We would like to avoid using such an algorithm in our project in order to keep processing costs at a minimum.
%This is useful for periodic \textit{identification}, where the system attempts to recognize who the user is without them claiming an identity first.
%For 

Several other researchers have also used Gunetti and Picardi's A and/or R distances \cite{Kolakowska2011, Messerman, meaningless, hu, davoudi2009, davoudi2010, superResults, Pinto2014, sliding}.
%NOTE WHICH OF THESE ARE INTERESTING?
Of these, especially Ferreira and Santos \cite{superResults} stand out as they attempted to tackle both the block size and computational performance problems of Gunetti and Picardi's \cite{gnp} study.
They used a block size of 250 keystrokes, achieving an Equal Error Rate (EER) of 1.4\%, meaning the FMR and FNMR are equal at that percentage.
They also mentioned that a specific setting gave a result of 0.5\% FMR and 2.7\% FNMR, which corresponds to an ANIA of 251 and an ANGA of 9259.
Considering the CA system's ANIA is 499, this amount of keystrokes may positively impact the CA system's imposter detection rate.
The ANGA is also in an acceptable range which should not lead to very many false rejections per day.

Other measures were also applied in \cite{Kaneko}, namely Euclidean distance, Manhattan distance, a proposed distance and Gaussian probability density function. Results showed that Euclidean distance gave the best result, however the experiment setting was writing a fixed Japanese text of around 200 keystrokes.
It is hard to know whether this would be true for the dataset to be used in our project due to the large differences in data collection methods.
%NOTE: Kolakowska not present in specialization project?

Machine learning has also been utilized in recent years, with with some of the research presenting promising results.
An example of this is Ahmed and Traore's work from 2007 \cite{Ahmed}, who used neural networks for classification.
Their system uses a neural networks combined with a key mapping technique in order to predict missing digraphs from a user's enrollment sample.
This means that a much smaller amount of different digraphs need to be recorded in the enrollment phase.
If a user types a digraph to be used for authentication which was never recorded for the reference, it can still be compared to the approximated values of the missing digraphs, based on the genuine user's actual recorded digraphs.


\subsection{Machine learning approaches}
"FAST" Shim uses random forest. Good results but hard to apply in practice according to \cite{KANG201572}

%NOTE: MENTION RESEARCH QUESTION 1.c.

\section{Overview}

%\begin{table}[h]
%\begin{tabular}{ |c|c|c|c|p{1.5cm}|p{2.1cm}|p{2cm}|c| } 
% \hline
% \bf Paper & \bf Block & \bf Users & \bf Uncontr. & \bf Method & \bf Perf. & \bf Notes & n-graphs\\ \hline
% \bf Messerman & 50 - 150 & 55 & Webmail & R\&A &  FAR 2.02\% FRR 1.84\% & adaptive user model & \\ \hline
% \bf Ferreira & 250 & 60 & Yes & R\&A & EER 1.4\% & Updates user profile, also triggers authentication asynch & \\ \hline
% Davoudi(2) & & & & & & & \\ \hline
% %Singh &- & - & - & - & - & STATIC AUTHENT. DONT BOTHER & \\ \hline
% Kaneko & ~200 & 51 & No & Euclidian & 0.66\% EER & Static fixed text, jap. & di \\ \hline
% Ahmed & 500 & 53 & Yes & Neural Networks & FAR 0.0152\% FRR 4.82\% ERR 2.45\% & & mono di\\\hline
% Gunetti & 800 & 40 & Webform & R\&A & FAR 0.005\% FRR 4.833\% & & 2,3,4\\ \hline
% \bf Hu et al. & 36 & 19 & Webform & R\&A, k-NN & FAR 0.045\% FRR 0.005\% & Static text & - \\ \hline
% 
%\end{tabular}
%\end{table}

%Machine learning

%Authentication algorithms



%\newpage
%
%The purpose of this chapter
%is to explain to the reader what knowledge is already
%available from the literature.
%
%The purpose of the related work chapter is to:
%\begin{itemize}
%\item Identify to what extent information identified in the 'Research questions'  section is provided in the literature.
%\item Give an overview of why/how the literature provides the answer to the research questions identified.
%\item Identify areas/ research questions where the literature appears to be weak or non-existent.
%\end{itemize}
%The Related Work Chapter is NOT:
%\begin{itemize}
%\item   A list of abstracts and summaries of more-or-less-relevant literature.
%\end{itemize}
%If you have
%\begin{itemize}
%\item   found some relevant literature
%\item   made summaries of what you have written
%\end{itemize}
%you should
%\begin{itemize}
%\item reorganize these summaries to focus on the research questions you have identified.
%\end{itemize}
%
%This chapter should include one subsection for each of the research
%questions identified in section \ref{research:questions}.  
%
%\section{Handling Potential problems}
%When searching for literature, you usually get too many hits or none at all...
%
%\paragraph{Question 1} I don't find any relevant literature.
%
%\paragraph{Answer 1.A}  Make a list of words, phrases, applications, abbreviations,
%organizations, terminology etc. relevant for your area of interest.
%Ask a librarian to sit with you for 20 minutes to formulate relevant
%queries to available databases.  Record your findings.
%
%\paragraph{Answer 1.B}  Go to the ACM (www.acm.org) or IEEE (www.ieee.org) web pages.
%Identify the SIGs (Special Interest Groups) of these organizations.
%Select the SIGs which looks the most interesting.
%Most SIGs publish one or more journals and/or organize workshops or conferences.
%Get hold of a few journals or proceedings and see if they're any interesting.
%
%
%\paragraph{Question 2}  I've found a lot of papers.
%They all look interesting, but I don't have time to read them all.
%
%\paragraph{Answer 2.A}  Narrow your search.  Be more specific in your search.  Read the abstracts of the relevant articles before you read the full papers.
%
%\paragraph{Answer 2B}  Find a citation index (e.g. \url{http://citeseer.ist.psu.edu/}.
%Read those papers with a high citation score first
%(a citation index rates papers according to 'academic popularity').  Alternatively,
%read those papers published in 'prestigious' conference proceedings or journals first.
%
%
%\paragraph{Control questions:}
%\begin{enumerate}
%\item Why can we have confidence that the most relevant literature has been identified?
%\item is the related literature grouped in a sensible way such that the reader gets a good understanding of 'existing knowledge' relating to th research questions/problem description?
%\item Is the chapter sufficiently comprehensive?
%\end{enumerate}

\chapter{Choice of methods (2-5 pages)}
\section{Literature study}
Even though a literature study already has been performed on the topic, the project period will begin with an additional literature study.
The existing researches will be reviewed in more extensive detail, applying the knowledge which has already been gained to decide exactly which PA techniques will be used in the project.
The techniques to be used must also be well understood before implementing them.
Especially the machine learning algorithms to be used will require more studying, due to inexperience with these.
Furthermore, as periodic authentication based on keystroke dynamics is an active research field, new studies may have been published which were not already covered in this document.


\section{Implementing CA statistical approach}

As mentioned in \cref{sec:related-CA}, Mondal's \cite{mondal} dataset will be used in this project, which means that no data collection will be performed.
Therefore, when the literature study is completed, the next activity will be to implement the first statistical approach (SA-1) from Mondal's experiments.
He describes 


%This section is to include a description of the methods to be used,
%including references to literature describing the methods to be used
%(e.g. qualitative, quantitative, interviews, surveys,
%questionnaire,  model building etc.)
%For each of the research questions to be addressed,
%the chapter is to explain why the method is
%\begin{itemize}
%\item appropriate
%\item likely to provide the desired knowledge/information.
%\end{itemize}


\chapter{Milestones, deliverables and resources (2-5 pages)}
%\begin{landscape}
%\begin{ganttchart}[
%hgrid,
%vgrid,
%x unit=2mm,
%time slot format=isodate
%]{2018-01-08}{2018-06-15}
%\gantttitlecalendar{month=name, week=2} \\
%\ganttbar{}{2018-01-14}{2018-01-17}
%\end{ganttchart}
%\end{landscape}


%\begin{landscape}
%\begin{ganttchart}[hgrid,
%                        vgrid,
%                        x unit=1.28mm,
%                        time slot format={isodate},
%                        ]{2018-01-08}{2018-06-15}
%           \gantttitlecalendar{year, month=name} \\
%           \ganttbar{Seminar}{2018-01-08}{2018-01-14} \\
%           \ganttbar{Review}{2018-01-15}{2018-01-21} \\
%           \ganttbar{Study CA}{2018-01-22}{2018-01-28} \\
%           \ganttbar{Feat. ext.}{2018-01-29}{2018-02-04} \\
%           \ganttbar{Train ref.}{2018-02-05}{2018-02-11} \\
%           \ganttbar{Probe proc.}{2018-02-12}{2018-02-18} \\
%           \ganttbar{Prep. alg.}{2018-02-19}{2018-02-25} \\
%           \ganttbar{Infl. CA}{2018-02-26}{2018-03-04} \\
%           \ganttbar{Perf. rep}{2018-03-05}{2018-03-11} \\
%           \ganttbar{Sim.}{2018-02-26}{2018-03-04} \\
%           \ganttbar{Analysis}{2018-02-26}{2018-03-04} \\
%           
%           %\ganttbar{Task 2}{2015-10}{2016-02} 
%      \end{ganttchart}
%\end{landscape}

%\begin{landscape}
%\begin{ganttchart}{1}{12}
%\gantttitle{2011}{12} \\
%\gantttitlelist{1,...,12}{1} \\
%\ganttgroup{Group 1}{1}{7} \\
%\ganttbar{Task 1}{1}{2} \\
%\ganttlinkedbar{Task 2}{3}{7} \ganttnewline
%\ganttmilestone{Milestone}{7} \ganttnewline
%\ganttbar{Final Task}{8}{12}
%\ganttlink{elem2}{elem3}
%\ganttlink{elem3}{elem4}
%\end{ganttchart}
%\end{landscape}


The purpose of this chapter is to convince the reader that you know exactly what to do.
This chapter gives a description of how the project is to be
broken down into smaller parts and activities.
\begin{enumerate}
\item  What is it you have to do in order to obtain the desired knowledge?
\item  What deliverables are to be produced (MSc thesis report, software,...)
\item  When are the various deliverables going to be available?
\end{enumerate}

For each deliverable, identify 4 versions, having an
'increasing' degree of completeness/quality.
Students are strongly recommended to review each others drafts.
For each version of a deliverable explain why and how this version is to
be better/more complete.  E.g. v1.0: my first draft -
chapter text includes 1/2 page summaries only.
v.2.0: Like v1.0, but comments by NN(who? fellow student)
has been incorporated. v3.0:....

This section is to include a preliminary table of contents for the MSc thesis
(only include 2 levels).

For each of the activities identified, specify
\begin{enumerate}
\item  the time you need to complete each activity both calendar time and 'man-hours'.
\item  hours needed by you
\item  things you need to buy (consumables)
\item  equipment, lab space or facilities you need access to
\item  contributions from others (e.g. survey/interview participants) and how much each will have to contribute in terms of resources (probably time)
\end{enumerate}
At the beginning of this section, provide a 2-3 line summary of the
resource requirements.  This is particularly useful if you have broken
down the task into a lot of small tasks.

\chapter{Feasibility study (1/2-3 pages)}
An analysis of why it is likely that the desired
results can be produced within the given time and
resource bounds.  This may include a description of
\begin{itemize}
\item similar projects completed by others and their 'resource consumption',
\item an attempt to answer parts of the research questions
\item the 'difficult' elements of the work and an explanation of why/how these problems can be solved.  
Alternatively you can explain an 'approximate' solution.
\end{itemize}

\chapter{Risk analysis (1/2-2 pages)}
%There is a certain risk of health issues hindering the project.
%Though I generally have no issues regarding health, the possibility of illness or injury can not be neglected.
This chapter contains a risk analysis for the project period.
An attempt to estimate probability and impact of undesired events has been made, and the result can be seen in \autoref{tab:risk-analysis}.
The state of the risks have been visualized in \autoref{tab:initial-risk} and \autoref{tab:residual-risk}, before and after preventive or remedial actions have been considered.
The colors used in the risk analysis are explained in \autoref{tab:colour-legend}, and probability and impact classes are explained in \autoref{tab:probability-classes} and \autoref{tab:impact-classes}, respectively.

\begin{table}[H]
\scriptsize
\caption{Risk analysis for project period}
\label{tab:risk-analysis}
\begin{tabular}{c| p{1.3cm}|p{1.5cm}|p{0.94cm}|p{2.5cm}|p{2.2cm}|p{1.7cm}|}
\hhline{~|------}
& \bf Identifier & Impl. CA & Illness & Impl. PA & Injury & Beh. sched.\\ \hhline{~|------|}
\bf & \bf Undesired event & Trouble implementing CA & Illness lasting a week or longer & Trouble incorporating a PA system & Physical injury preventing progress & Falling far behind schedule\\ \hhline{~|------|} 
& \bf Probable Causes & Lack of understanding regarding original CA system; software bugs & Infection; other & Mathematical complexity; inexperience with Matlab & Severely injuring both hands or arms in a sport climbing accident & Too large workload; poor time management; burnout\\ \hhline{~|------|}
\multirow{3}{*}{\rotatebox{90}{\tiny INITIAL\,}} & \bf Probability & 3 & 2 & 5 & 1 & 3  \\ \hhline{~|------|}
& \bf Severity & 4 & 2 & 2 & 4 & 3 \\ \hhline{~|------|}
& \bf Risk Level & \cellcolor{red!50} & \cellcolor{green!50} & \cellcolor{red!50} & \cellcolor{yellow!50} & \cellcolor{yellow!50}\\ \hhline{~|------|}
& \bf Prevention/ Remediation& Ask for guidance from supervisor or the original author if necessary & None & Ask for guidance from supervisor; study Matlab implementations of machine learning and statistical models early in project period; prioritize another PA system & Only use highly experienced belayers during the project period; avoid climbing high-risk routes; request extension of deadline if injury occurs & Discuss which parts of the project can be omitted; extend working hours; socialize to prevent burnout\\ \hhline{~|------|}
\multirow{3}{*}{\rotatebox{90}{\tiny RESIDUAL\,}}& \bf Probability & 3 & 2 & 4 & 1 & 2\\ \hhline{~|------|}
& \bf Severity & 1 & 2 & 2 & 3 & 2\\ \hhline{~|------|}
& \bf Risk Level & \cellcolor{green!50} & \cellcolor{green!50} & \cellcolor{yellow!50} & \cellcolor{green!50} & \cellcolor{green!50}\\
\hhline{~|------|}

%add more rows as required

\end{tabular}
\end{table}

\begin{table}[H]
\centering
\scriptsize
\caption{Initial risk matrix}
\label{tab:initial-risk}
\begin{tabular}{|m{1.75cm}|m{1.75cm}|m{1.75cm}| m{1.75cm} |m{1.75cm}| m{1.75cm}|m{0cm}}
\hhline{|------|} \bf Probability/ Impact & \bf 1-Very unlikely & \bf 2-Unlikely & \bf 3-Possible & \bf 4-Likely & \bf 5-Very likely & \\[10pt]

\hhline{|------|} \bf 4-Catastrophic & \cellcolor{yellow!50} \centering Injury & \cellcolor{red!50}  & \cellcolor{red!50} \centering Impl. CA & \cellcolor{red!50} &\cellcolor{red!50} & \\ [10pt]

\hhline{|------|} \bf 3-Critical &\cellcolor{green!50} & \cellcolor{yellow!50} & \cellcolor{yellow!50} \centering Beh. sched. & \cellcolor{red!50} &\cellcolor{red!50} & \\ [10pt]

\hhline{|------|} \bf 2-Major & \cellcolor{green!50} & \cellcolor{green!50} \centering Illness & \cellcolor{yellow!50} &\cellcolor{yellow!50} &\cellcolor{red!50} \centering Impl. PA & \\[10pt]

\hhline{|------|} \bf 1-Minor & \cellcolor{green!50} & \cellcolor{green!50} & \cellcolor{green!50} &\cellcolor{yellow!50} &\cellcolor{yellow!50} & \\ [10pt]
\hhline{|------|}
\end{tabular} \\
\end{table}

\begin{table}[H]
\centering
\scriptsize
\caption{Residual risk matrix}
\label{tab:residual-risk}
\begin{tabular}{|m{1.75cm}|m{1.75cm}|m{1.75cm}| m{1.75cm} |m{1.75cm}| m{1.75cm}|m{0cm}}
\hhline{|------|} \bf Probability/ Impact & \bf 1-Very unlikely & \bf 2-Unlikely & \bf 3-Possible & \bf 4-Likely & \bf 5-Very likely & \\[10pt]

\hhline{|------|} \bf 4-Catastrophic & \cellcolor{yellow!50} & \cellcolor{red!50} & \cellcolor{red!50} & \cellcolor{red!50} &\cellcolor{red!50} & \\ [10pt]

\hhline{|------|} \bf 3-Critical &\cellcolor{green!50} \centering Injury & \cellcolor{yellow!50} & \cellcolor{yellow!50} & \cellcolor{red!50} &\cellcolor{red!50} & \\ [10pt]

\hhline{|------|} \bf 2-Major & \cellcolor{green!50} & \cellcolor{green!50} \centering Beh. sched.; Illness & \cellcolor{yellow!50} &\cellcolor{yellow!50} \centering Impl. PA &\cellcolor{red!50} & \\[10pt]

\hhline{|------|} \bf 1-Minor & \cellcolor{green!50} & \cellcolor{green!50} & \cellcolor{green!50} \centering Impl. CA &\cellcolor{yellow!50} &\cellcolor{yellow!50} & \\ [10pt]
\hhline{|------|}
\end{tabular} \\
\end{table}

The analysis includes events with significant probability and impact.
As seen in tables 1-3, there are no residual risks with red risk level.
The event with a yellow residual risk level is Impl. PA.
While the impact of this event is not critical, a high probability remains.
Incorporating PA systems into the CA system is the main task of the master thesis, and a high probability of having trouble with this is only natural.
Therefore, trying to remediate this event any further is part of the project itself.

\begin{table}[H]
\centering
%\scriptsize
\caption{Risk matrix color legend}
\label{tab:colour-legend}
\begin{tabular}{|p{2cm}|p{10cm}|}
\hline \bf Colour & \bf Legend \\
\hline \cellcolor{red! 50} & Not acceptable - Risk reduction required \\ [10pt]
\hline \cellcolor{yellow! 50} & Acceptable to a some degree. Consider further risk reduction. \\[10pt]
\hline \cellcolor{green! 50} & Acceptable. \\ [10pt]
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Probability classes legend}
\label{tab:probability-classes}
\begin{tabular}{ p{2cm} p{3cm} p{8cm}}
\hline \bf Rank & \bf Probability class & \bf Description \\
\hline 1 & Very unlikely & Below 10 \% chance of occurring \\
2 & Unlikely & Between 10 - 25 \% chance of occurring \\
3 & Possible & Between 25 - 75 \% chance of occurring \\
4 & Likely & Between 75 - 90 \% chance of occurring \\
5 & Very likely & Over 90\% chance of occurring \\

\hline

\end{tabular}
\end{table}

%Severity Classes Legend
\begin{table}[H]
\centering
\caption{Impact classes legend}
\label{tab:impact-classes}
\begin{tabular}{ p{2cm} p{3cm} p{8cm}}
\hline \bf Rank & \bf Severity class & \bf Description \\

\hline 4 & Catastrophic & Events lead to complete project failure. \\
3 & Critical & Events lead to very large set-backs, with significant negative impact on end result.\\
2 & Major & Events lead to important parts of the project being negatively affected. \\
1 & Minor & Events lead to smaller parts of minimal importance being negatively affected or omitted.\\
\hline
\end{tabular}
\end{table}


%\begin{itemize}
%\item What can possibly go wrong when you do your project?
%\item How do you intend to reduce impact of/solve these problems?
%\end{itemize}



\chapter{Ethical and legal considerations (1/4-1 page)}
Doing research in the biometrics field can bring ethical problems and legal considerations as it often involves collecting highly sensitive information from volunteers contributing to the project.
This is especially true for uncontrolled free-text keystroke dynamics, as the data collected involves not only measurement of the biometric trait, but also information that can be analyzed to uncover the semantics and context of what the participants typed on their private computers as long as the BeLT software was recording.

BeLT's automatic password censoring is one measure that decreases the amount of highly sensitive information collected to a certain degree.
Still, depending on the software, some password fields may not have been detected by BeLT, resulting in keystrokes involved in passwords being recorded without censoring. 
Even if all passwords were censored, an abundance of information was recorded, and sensitive information is bound to be present in the database.

If new data will be collected for this project, all of this information must be fully understood by participants before they consent.
In the case of us using a database from previous research, participants have already been informed of their data being used for research purposes and have given their consent.

Regardless of whether which database we use, we will not open raw samples unless it is necessary for project progression.
If we do access raw samples, we will not analyze the data for the purpose of uncovering what the participant was writing.
In case any sensitive information written by a participant is uncovered, this information will by no means ever be shared with anyone who are not members of the project (being the author and the supervisor).
If an excerpt of a sample including sensitive information is to be included in the thesis paper as an example, any and all sensitive information will be manually censored beforehand.

Under no circumstances will access to the database be given to anybody not involved in the project.
When the project period is over, the database and any material containing sensitive information will be removed from the project members' devices, and stored on a safe university server for future research purposes.


%The purpose of this chapter is to convince the
%reader and your self that your project activities are
%\begin{itemize}
%\item legal
%\item ethical, e.g. don't use/distribute/collect etc. data in such a way that individuals may suffer.
%\end{itemize}
%For example, if you are planning to do reverse engineering activities, surveys, PENTESTING- (both technical and based on social engineering techniques) you need to be particularly careful and check with the appropriate experts and authorities if the activity is permitted.  An explanation of why your project is both legal and ethical should be given in this chapter.
%
%If you need permission (e.g. because you will be collecting or processing privacy related information), 
%you should  include the appropriate applications/application forms and ensure that these applications 
%are submitted well before you need the permission.

%9.  Bibliography (1-3 pages)

\chapter{The bibliography}
References/bibliography
Reference to other peoples work MUST include:
\begin{itemize}
\item Name of author(s)  or name of responsible organization (if the document does not have a named author.
\item Title of document.
\item Where published.
\item Year of publication.
\end{itemize}

There are many different types of documents (article, book etc.).
In many cases, the required/optional fields may differ.
See e.g. the BibTeX entry of wikipedia (\url{http://en.wikipedia.org/wiki/BibTeX}).
The bibliography file 
\verb+imt4441.bib+ 
contains an example.

NOTE: A url on its own is no good!
It must be possible to locate the reference even if a link goes dead!

\appendix
\chapter{Known problems with MikTeX and TeXnicCenter}
\section{Hig logo xor url's}
\paragraph{Problem}
Using MikTeX (version 2.6) in combination with TeXnicCenter you may experience the following problems:

You have to choose between being able to get the HIG logo on the front page (Use the TeXnic translation LaTeX => ps => pdf)  and getting visible url's (use the LaTeX => PDF translation option).

\paragraph{Possible solution 1}
use \verb+\usepackage[dvips]{graphicx}+ in combination with TeXnicCenter translation LaTeX => PS, and use Adobe distiller to convert from PS to PDF.  This should give both logo and URL (but no line breaks in URL's).

\paragraph{Possible solution 2}
Use \verb+epstopdf.exe+ to convert \verb+higlogo.eps+ to \verb+higlogo.pdf+.
Modify the file \verb+gucmasterthesis.cls+ to include \verb+higlogo.pdf+ instead of \verb+higlogo+.
Select the TeXnicCenter translation \verb+LaTeX => PDF+.


\section{\LaTeX/AFPL Ghostscript crashes}
\paragraph{Problem}
The build window prints out operand stack, execution and dictionary stack before concluding with the message 
'\verb+Unrecoverable error, exit code 1+'.
\paragraph{Possible solution}
Use the TeXnicCenter translation 'LaTeX => PDF'.

%\chapter{Project description evaluation criteria}


\bibliographystyle{plain}
%\bibliographystyle{gucmasterthesis}
\bibliography{imt4441}



\end{document}





%IEEE computer society keywords
%http://www.computer.org/portal/site/ieeecs/menuitem.c5efb9b8ade9096b8a9ca0108bcd45f3/index.jsp?&pName=ieeecs_level1&path=ieeecs/publications/author/keywords&file=ACMtaxonomy.xml&xsl=generic.xsl&
